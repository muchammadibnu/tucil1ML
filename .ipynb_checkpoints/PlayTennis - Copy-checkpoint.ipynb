{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "Berikut ini merupakan implementasi machine learning pada dataset playtennis menggunakan library scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup Library dan Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>10.26</td>\n",
       "      <td>14.71</td>\n",
       "      <td>66.20</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09882</td>\n",
       "      <td>0.09159</td>\n",
       "      <td>0.035810</td>\n",
       "      <td>0.020370</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.07005</td>\n",
       "      <td>...</td>\n",
       "      <td>10.88</td>\n",
       "      <td>19.48</td>\n",
       "      <td>70.89</td>\n",
       "      <td>357.1</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.16360</td>\n",
       "      <td>0.071620</td>\n",
       "      <td>0.04074</td>\n",
       "      <td>0.2434</td>\n",
       "      <td>0.08488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>10.75</td>\n",
       "      <td>14.97</td>\n",
       "      <td>68.26</td>\n",
       "      <td>355.3</td>\n",
       "      <td>0.07793</td>\n",
       "      <td>0.05139</td>\n",
       "      <td>0.022510</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>...</td>\n",
       "      <td>11.95</td>\n",
       "      <td>20.72</td>\n",
       "      <td>77.79</td>\n",
       "      <td>441.2</td>\n",
       "      <td>0.1076</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.097550</td>\n",
       "      <td>0.03413</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.06769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>11.89</td>\n",
       "      <td>17.36</td>\n",
       "      <td>76.20</td>\n",
       "      <td>435.6</td>\n",
       "      <td>0.12250</td>\n",
       "      <td>0.07210</td>\n",
       "      <td>0.059290</td>\n",
       "      <td>0.074040</td>\n",
       "      <td>0.2015</td>\n",
       "      <td>0.05875</td>\n",
       "      <td>...</td>\n",
       "      <td>12.40</td>\n",
       "      <td>18.99</td>\n",
       "      <td>79.46</td>\n",
       "      <td>472.4</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>0.071530</td>\n",
       "      <td>0.08946</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.06033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>11.33</td>\n",
       "      <td>14.16</td>\n",
       "      <td>71.79</td>\n",
       "      <td>396.6</td>\n",
       "      <td>0.09379</td>\n",
       "      <td>0.03872</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.1954</td>\n",
       "      <td>0.05821</td>\n",
       "      <td>...</td>\n",
       "      <td>12.20</td>\n",
       "      <td>18.99</td>\n",
       "      <td>77.37</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.1259</td>\n",
       "      <td>0.07348</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>0.01111</td>\n",
       "      <td>0.2758</td>\n",
       "      <td>0.06386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>14.86</td>\n",
       "      <td>23.21</td>\n",
       "      <td>100.40</td>\n",
       "      <td>671.4</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.169700</td>\n",
       "      <td>0.088780</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.06672</td>\n",
       "      <td>...</td>\n",
       "      <td>16.08</td>\n",
       "      <td>27.78</td>\n",
       "      <td>118.60</td>\n",
       "      <td>784.7</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>0.46480</td>\n",
       "      <td>0.458900</td>\n",
       "      <td>0.17270</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.08701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "345        10.26         14.71           66.20      321.6          0.09882   \n",
       "144        10.75         14.97           68.26      355.3          0.07793   \n",
       "275        11.89         17.36           76.20      435.6          0.12250   \n",
       "276        11.33         14.16           71.79      396.6          0.09379   \n",
       "194        14.86         23.21          100.40      671.4          0.10440   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "345           0.09159        0.035810             0.020370         0.1633   \n",
       "144           0.05139        0.022510             0.007875         0.1399   \n",
       "275           0.07210        0.059290             0.074040         0.2015   \n",
       "276           0.03872        0.001487             0.003333         0.1954   \n",
       "194           0.19800        0.169700             0.088780         0.1737   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "345                 0.07005  ...         10.88          19.48   \n",
       "144                 0.05688  ...         11.95          20.72   \n",
       "275                 0.05875  ...         12.40          18.99   \n",
       "276                 0.05821  ...         12.20          18.99   \n",
       "194                 0.06672  ...         16.08          27.78   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "345            70.89       357.1            0.1360            0.16360   \n",
       "144            77.79       441.2            0.1076            0.12230   \n",
       "275            79.46       472.4            0.1359            0.08368   \n",
       "276            77.37       458.0            0.1259            0.07348   \n",
       "194           118.60       784.7            0.1316            0.46480   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "345         0.071620               0.04074          0.2434   \n",
       "144         0.097550               0.03413          0.2300   \n",
       "275         0.071530               0.08946          0.2220   \n",
       "276         0.004955               0.01111          0.2758   \n",
       "194         0.458900               0.17270          0.3000   \n",
       "\n",
       "     worst fractal dimension  \n",
       "345                  0.08488  \n",
       "144                  0.06769  \n",
       "275                  0.06033  \n",
       "276                  0.06386  \n",
       "194                  0.08701  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer(as_frame = True)\n",
    "full_data_X, full_data_Y = load_breast_cancer(return_X_y = True, as_frame=True)\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(full_data_X, full_data_Y, \n",
    "                                                                train_size=0.8, test_size=0.2)\n",
    "\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in X_train_full.columns if \n",
    "                    X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "X_train_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Preprocessing and Pipelining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer()\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from id3 import Id3Estimator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define model\n",
    "modelDtl = tree.DecisionTreeClassifier(random_state=0)\n",
    "modelID3 = Id3Estimator()\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "modelLogistic = LogisticRegression(random_state=0, max_iter=100)\n",
    "modelNeural = MLPClassifier(random_state=0, max_iter=300)\n",
    "modelSVM = make_pipeline(StandardScaler(), SVC(gamma='auto', random_state=0))\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "dtl = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', modelDtl)\n",
    "                     ])\n",
    "\n",
    "modID3 = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', modelID3)\n",
    "                     ])\n",
    "\n",
    "modelKmeans = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', kmeans)\n",
    "                     ])\n",
    "\n",
    "modlogistic = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', modelLogistic)\n",
    "                     ])\n",
    "\n",
    "modNeural = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', modelNeural)\n",
    "                     ])\n",
    "\n",
    "modSVM = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', modelSVM)\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Fitting and predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This OneHotEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5934b3131ed1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m dot_data = tree.export_graphviz(modelDtl, \n\u001b[0;32m      6\u001b[0m                   \u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'preprocessor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformers_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m    .named_steps['onehot'].get_feature_names(X_train_full.columns))\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python 36-64\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[1;34m(self, input_features)\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[0mArray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         \"\"\"\n\u001b[1;32m--> 576\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m         \u001b[0mcats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minput_features\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python 36-64\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python 36-64\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1020\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This OneHotEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "# Preprocessing of training data, fit model \n",
    "dtl.fit(X_train_full, y_train)\n",
    "#r = tree.export_text(model, feature_names = [d for d in data.feature_names])\n",
    "dot_data = tree.export_graphviz(modelDtl, \n",
    "                  feature_names=dtl.named_steps['preprocessor'].transformers_[1][1]\\\n",
    "   .named_steps['onehot'].get_feature_names(X_train_full.columns))\n",
    "graph = graphviz.Source(dot_data)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "predsDtl = dtl.predict(X_valid_full)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3 Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from id3 import export_graphviz\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "modID3.fit(X_train_full, y_train)\n",
    "\n",
    "#r = tree.export_text(model, feature_names = [d for d in data.feature_names])\n",
    "dot_treeID3 = export_graphviz(modelID3.tree_, 'graph.dot', \n",
    "                  feature_names=dtl.named_steps['preprocessor'].transformers_[1][1]\\\n",
    "   .named_steps['onehot'].get_feature_names(X_train_full.columns), \n",
    "                  )\n",
    "with open(\"graph.dot\") as f:\n",
    "    dot_graphID3 = f.read()\n",
    "graphID3 = graphviz.Source(dot_graphID3)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "predsID3 = modID3.predict(X_valid_full)\n",
    "\n",
    "graphID3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKmeans.fit(X_train_full, y_train)\n",
    "\n",
    "predsKmeans = ['Yes' if item==1 else 'No' for item in modelKmeans.predict(X_valid_full)]\n",
    "predsKmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modlogistic.fit(X_train_full, y_train)\n",
    "\n",
    "predsLogistic = modlogistic.predict(X_valid_full)\n",
    "predsLogistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modNeural.fit(X_train_full, y_train)\n",
    "predsNeural = modNeural.predict(X_valid_full)\n",
    "predsNeural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modSVM.fit(X_train_full, y_train)\n",
    "predsSVM = modSVM.predict(X_valid_full)\n",
    "predsSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Accuracy and F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "accuracy = [accuracy_score(y_valid, predsDtl),accuracy_score(y_valid, predsID3),accuracy_score(y_valid, predsKmeans),accuracy_score(y_valid, predsLogistic),accuracy_score(y_valid, predsNeural),accuracy_score(y_valid, predsSVM)]\n",
    "f1 = [f1_score(y_valid, predsDtl, pos_label='Yes'), f1_score(y_valid, predsID3, pos_label='Yes'), f1_score(y_valid, predsKmeans, pos_label='Yes'), f1_score(y_valid, predsLogistic, pos_label='Yes'), f1_score(y_valid, predsNeural, pos_label='Yes'), f1_score(y_valid, predsSVM, pos_label='Yes')]\n",
    "score_data = {'accuracy': accuracy, 'f1': f1}\n",
    "score = pd.DataFrame(data = score_data, index=['Decision Tree Learning', 'ID3 Estimator', 'K-Means', 'Logistic Regression', 'Neural Network', 'SVM'])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
